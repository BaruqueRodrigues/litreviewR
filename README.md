
<!-- README.md is generated from README.Rmd. Please edit that file -->

# ğŸ“š litreviewR

O **`litreviewR`** Ã© um pacote R que automatiza o processo de **revisÃ£o
de literatura cientÃ­fica** e prepara suas referÃªncias e textos para
anÃ¡lises estruturadas com modelos de linguagem (LLMs/SLMs) e anÃ¡lise de
tÃ³picos. Ideal para pesquisadores e gestores pÃºblicos que precisam
organizar, baixar e interpretar grandes volumes de literatura com
**baixo esforÃ§o manual**.

------------------------------------------------------------------------

## ğŸš€ O que o pacote faz

- LÃª arquivos `.bib` e estrutura as referÃªncias (`gera_referencia`)

- Busca o DOI automaticamente quando ausente (`descobre_doi_por_titulo`)

- Baixa artigos **nacionais** (SciELO, ANPOCS etc) via
  `baixa_pdf_aberto()`

- Baixa artigos **internacionais** via Sci-Hub com `baixa_pdf_scihub()`

- Usa **roteamento inteligente** com `baixa_pdf_auto()` para escolher o
  melhor mÃ©todo de download

- Extrai **resumos** dos PDFs para avaliaÃ§Ã£o manual
  (`gera_csv_resumos_para_anotacao`)

- Cria **agrupamentos temÃ¡ticos** dos tÃ³picos via anotaÃ§Ã£o ou clustering
  (`agrupa_topicos`)

- Gera **modelos de tÃ³picos** com LDA, STM ou NMF (`modela_topicos`)

- ## Roda todo o pipeline de anÃ¡lise com `roda_analise_topicos`

## ğŸš€ InstalaÃ§Ã£o

VocÃª pode instalar a versÃ£o de desenvolvimento diretamente do GitHub
com:

``` r
# Instale o devtools, se ainda nÃ£o tiver
install.packages("devtools")

# Instale o litreviewR
devtools::install_github("BaruqueRodrigues/litreviewR")
```

## ğŸ§  Pipeline automÃ¡tico de download

A funÃ§Ã£o `baixa_pdf_auto()` identifica automaticamente a origem do
artigo:

- **Artigos nacionais**: detectados por domÃ­nio ou `publisher` no
  CrossRef â†’ `baixa_pdf_aberto()`
- **Artigos internacionais** ou com paywall â†’ `baixa_pdf_scihub()`

``` r
library(litreviewR)

# LÃª o .bib
referencias <- gera_referencia("minhas_referencias.bib")

# Baixa os PDFs automaticamente
baixa_pdf_auto(referencias, diretorio = "pdfs")
```

ğŸ§  Pipeline completo de anÃ¡lise de tÃ³picos

Se vocÃª jÃ¡ possui os PDFs, use roda_analise_topicos() para:

Ler os arquivos PDF Preprocessar os textos Rodar um modelo de tÃ³picos
(LDA, STM, NMF) Retornar os principais termos por tÃ³pico

``` r
resultado <- roda_analise_topicos(
  pasta_pdfs = "pdfs",
  k = 10,
  method = "lda",       # ou "stm", "nmf"
  idioma = "portuguese",
  modo = "agrupado"
)

# Ver os tÃ³picos
resultado$topicos
```

## âœ¨ FunÃ§Ãµes principais

### Para Pegar artigos

ğŸ“š gera_referencia()

Para quÃª serve? Transforma um arquivo .bib (BibTeX) em uma lista
organizada com tÃ­tulo, DOI (se existir) e um ID amigÃ¡vel para nomear
arquivos.

Caso prÃ¡tico: â€œBaixei 100 referÃªncias do Mendeley e quero transformar
isso em uma lista de tarefas para baixar os artigos automaticamente.â€

``` r
# Extrai as referÃªncias do .bib
refs <- gera_referencia("referencias.bib")
```

ğŸ‡§ğŸ‡· baixa_pdf_aberto()

Para quÃª serve? Baixa o PDF de artigos nacionais de acesso aberto, como
da SciELO, ANPOCS, USP e outros repositÃ³rios acadÃªmicos brasileiros.

Caso prÃ¡tico: â€œTenho vÃ¡rios artigos da Revista Dados e OpiniÃ£o PÃºblica,
que jÃ¡ sÃ£o abertos. NÃ£o preciso do Sci-Hub.â€

``` r
# Baixa um artigo nacional (SciELO)
baixa_pdf_aberto(refs)
```

ğŸŒ baixa_pdf_scihub()

Para quÃª serve? Baixa o PDF de artigos internacionais ou com paywall
usando o Sci-Hub, a partir do DOI.

Caso prÃ¡tico: â€œPreciso do PDF de um artigo da Cambridge University
Press, mas meu instituto nÃ£o tem acesso.â€

``` r
baixa_pdf_scihub(refs[[10]], diretorio = "pdfs")
```

ğŸ§  baixa_pdf_auto()

Para quÃª serve? Escolhe automaticamente o melhor mÃ©todo de download, com
base no DOI ou no tÃ­tulo, e no paÃ­s/origem do artigo.

Caso prÃ¡tico: â€œTenho um mix de artigos nacionais e internacionais. SÃ³
quero que o script descubra onde baixar.â€

``` r
baixa_pdf_auto(refs, diretorio = "pdfs")
```

### Para Analisar artigos

ğŸ“„ gera_csv_resumos_para_anotacao()

Para quÃª serve? Quando vocÃª tem dezenas de PDFs e quer ler sÃ³ os resumos
para organizar em Ã¡reas temÃ¡ticas ou correntes teÃ³ricas.

Caso prÃ¡tico: â€œSou coordenador de pesquisa e preciso dividir 120 artigos
entre 3 assistentes. Quero que cada um anote qual Ã¡rea do conhecimento o
artigo pertence.â€

``` r
# Gera CSV com resumos dos PDFs para anotaÃ§Ã£o manual
gera_csv_resumos_para_anotacao("pdfs", caminho_saida = "anotacao.csv")
```

ğŸ§  agrupa_topicos()

Para quÃª serve? Agrupa os tÃ³picos extraÃ­dos automaticamente em
categorias maiores, usando ou um arquivo CSV manual ou agrupamento
automÃ¡tico com clustering.

Caso prÃ¡tico: â€œExtraÃ­ 15 tÃ³picos de uma coleÃ§Ã£o de artigos. Agora quero
agrupÃ¡-los em 3 grandes correntes: institucionalismo, economia polÃ­tica
e opiniÃ£o pÃºblica.â€

``` r
# Agrupa tÃ³picos manualmente ou via clustering
agrupa_topicos(topicos = resultado$topicos, metodo = "cluster", n_clusters = 4)
```

ğŸ§¾ extrai_topicos()

Para quÃª serve? Roda um modelo LDA simples a partir de PDFs e retorna os
principais termos por tÃ³pico.

Caso prÃ¡tico: â€œBaixei os PDFs, agora quero uma ideia geral sobre os
temas que aparecem mais nos artigos.â€

``` r
topicos <- extrai_topicos("pdfs", k = 8, modo = "agrupado")
```

ğŸ— cria_dtm() + ğŸ§© modela_topicos()

Para quÃª servem? Separadamente permitem mais controle e personalizaÃ§Ã£o
sobre o pipeline. Use quando quiser testar diferentes abordagens com a
mesma base textual.

Caso prÃ¡tico: â€œQuero comparar o desempenho de LDA com NMF sobre a mesma
base de documentos.â€

``` r
dtm <- cria_dtm("pdfs", idioma = "portuguese")
modelo_lda <- modela_topicos(dtm, k = 10, method = "lda")
modelo_nmf <- modela_topicos(dtm, k = 10, method = "nmf")
```

``` r
# metadados deve conter colunas como 'ano_publicacao'
modelo_stm <- modela_topicos(dtm, k = 10, method = "stm", metadados = dados_artigos)
```

ğŸ¤– modela_topicos(method = â€œstmâ€) + metadados

Para quÃª serve? Permite usar variÃ¡veis como ano, autor, tipo de
periÃ³dico como covariÃ¡veis no modelo, com o mÃ©todo STM.

Caso prÃ¡tico: â€œQuero ver se os temas mudam com o tempo, comparando os
tÃ³picos de artigos publicados antes e depois de 2010.

## ğŸ”§ Em desenvolvimento

- IntegraÃ§Ã£o com modelos LLMs e SLMs (GPT, Claude, BERT etc)

  - ClassificaÃ§Ã£o temÃ¡tica automÃ¡tica

  - SumarizaÃ§Ã£o de artigos

  - ExtraÃ§Ã£o de tÃ³picos

- VisualizaÃ§Ãµes com Shiny ou Quarto

- Mapeamento de co-citaÃ§Ãµes e redes semÃ¢nticas

## ğŸ‘¤ Autor

Desenvolvido porÂ [Baruque
Rodrigues](https://github.com/baruqrodrigues)  
Coordenador de Operacoes e cientista de dados interessado automacoes,
money and politics, estatistica forense e NLP.

## ğŸ“œ LicenÃ§a

MIT Â© 2025 â€” VocÃª pode usar, modificar e redistribuir livremente com os
devidos crÃ©ditos.
